# Ribault – Agent & Developer Guide

## Overview

Ribault is a compiler and runtime system for implicit parallelism. It compiles a Haskell-subset language (.hsk) into dataflow graphs executed on the Trebuchet (TALM) interpreter, a multi-PE (processing element) dataflow machine. Serial regions are compiled into **superinstructions** (shared libraries called at runtime via FFI), while parallel structure is expressed as dataflow wiring between instructions.

---

## Repository Structure

```
Ribault/
├── src/                          Haskell compiler source
│   ├── Analysis/                 Frontend: lexer, parser, semantic analysis
│   │   ├── Lexer.x               Alex lexer specification
│   │   ├── Parser.y              Happy parser specification
│   │   ├── Syntax.hs             AST data types
│   │   ├── Semantic.hs           Scope checking, type inference, super naming
│   │   ├── AST-gen.hs            AST → GraphViz DOT
│   │   └── MainAST.hs            CLI entry: analysis executable
│   └── Synthesis/                Backend: dataflow graph construction & codegen
│       ├── Types.hs              NodeId, PortId, Edge, DGraph
│       ├── Port.hs               Port abstraction and edge builders
│       ├── Node.hs               Dataflow instruction types (NAdd, NSteer, NSuper, …)
│       ├── Unique.hs             Fresh ID generation monad
│       ├── Builder.hs            AST → dataflow graph lowering (40 KB, largest file)
│       ├── Codegen.hs            Dataflow graph → TALM assembly (.fl text)
│       ├── GraphViz.hs           Dataflow graph → DOT (full and cleaned views)
│       ├── SuperExtract.hs       Extract #BEGINSUPER/#ENDSUPER blocks from AST
│       ├── SupersEmit.hs         Generate Supers.hs module with FFI exports
│       ├── MainCode.hs           CLI entry: codegen executable
│       ├── MainGraph.hs          CLI entry: synthesis executable
│       └── MainSupers.hs         CLI entry: supersgen executable
│
├── TALM/                         Trebuchet interpreter and assembler (vendored)
│   ├── interp/                   C interpreter
│   │   ├── interp.c              Main runtime (~90 KB): scheduler, dispatch, supers FFI
│   │   ├── include/interp.h      Data structures: oper (uint64_t tag), instr_t, marker_t
│   │   ├── loader.c              .flb binary loader
│   │   ├── dfmem.c               Operand memory management
│   │   ├── queue.c / queue.h     Inter-PE communication queues
│   │   ├── treb_functions.c      Helper APIs (thread ID, timing)
│   │   ├── cas.c                 Atomic compare-and-swap
│   │   └── Makefile              Builds the interp binary
│   └── asm/                      FlowASM assembler (Python)
│       ├── assembler.py          CLI: .fl → .flb (binary) + .pla (placement)
│       ├── flowasm.py            Core assembler: lexing, instruction encoding
│       ├── preprocessor.py       Macro language (callgroup, superinst, placeinpe, loops)
│       └── scheduler.py          Auto-placement heuristics → _auto.pla
│
├── tools/                        Supers build infrastructure
│   ├── build_supers.sh           Master script: .hsk → Supers.hs → libsupers.so
│   ├── alias_supers.py           Rename FFI exports to avoid symbol collisions
│   └── fix_execstack.py          Clear PT_GNU_STACK execute flag in ELF
│
├── test/                         Test programs (.hsk) and generated artifacts
│   ├── *.hsk                     30+ test programs (hello_world, fibonacci, mergesort, …)
│   ├── ast-output/               Generated AST DOT files
│   ├── ast-images/               Rendered AST PNGs
│   ├── df-output/                Generated dataflow DOT files
│   ├── df-images/                Rendered dataflow PNGs
│   ├── talm/                     Generated TALM assembly (.fl files)
│   └── supers/                   Per-program Supers.hs + libsupers.so
│
├── scripts/                      Benchmarking and analysis
│   ├── run_all.sh                Master benchmark runner (configurable)
│   ├── paper_figures.py          Generate all publication figures
│   ├── gen_paper_fig2_fig4.py    Pipeline and DFG diagram figures
│   ├── merge_sort_TALM_vs_Haskell/   MergeSort benchmark scripts
│   ├── dyck/                     Dyck sequence benchmark scripts
│   ├── fibonacci/                Fibonacci benchmark scripts
│   ├── matmul/                   Matrix multiplication benchmark scripts
│   └── graph_coloring/           Graph coloring benchmark scripts
│
├── build/                        GHC shim for RTS discovery (generated by make supers_prepare)
├── RESULTS/                      Benchmark results, metrics CSVs, plots, paper figures
├── Makefile                      Build orchestration
├── codegen                       Executable: .hsk → .fl (TALM assembly)
├── analysis                      Executable: .hsk → AST DOT
├── synthesis                     Executable: .hsk → dataflow DOT
└── supersgen                     Executable: .hsk → Supers.hs
```

---

## Compilation Pipeline

```
                     ┌──────────────────────────────────────────────────────────┐
                     │                    Source Program (.hsk)                 │
                     └────────────────────────┬─────────────────────────────────┘
                                              │
                          ┌───────────────────┼───────────────────┐
                          ▼                   ▼                   ▼
                     ┌─────────┐        ┌──────────┐        ┌──────────┐
                     │ analysis│        │ codegen  │        │supersgen │
                     └────┬────┘        └────┬─────┘        └────┬─────┘
                          │                  │                   │
                     AST (.dot)         .fl (TALM asm)     Supers.hs
                          │                  │                   │
                     [graphviz]         [assembler.py]    [build_supers.sh]
                          │                  │                   │
                      AST.png          .flb + .pla         libsupers.so
                                             │                   │
                                             └─────────┬─────────┘
                                                       ▼
                                              ┌────────────────┐
                                              │  TALM interp   │
                                              │  (N PEs)       │
                                              └────────────────┘
```

### Stage 1: Frontend (Lexer → Parser → Semantic)

1. **Lexer** (`src/Analysis/Lexer.x`, alex): Tokenizes `.hsk` source. Handles keywords (`let`, `if`, `case`), operators, literals, and `#BEGINSUPER`/`#ENDSUPER` markers.

2. **Parser** (`src/Analysis/Parser.y`, happy): Produces an AST. Supports function definitions, pattern matching, lambdas, if/then/else, case/of, let/in, list comprehensions, tuples, binary operators, and super blocks.

3. **Semantic analysis** (`src/Analysis/Semantic.hs`): Checks scope (undefined variables), arity (argument counts), duplicates, and performs lightweight type inference. Assigns numeric super names: `s0`–`s3` are reserved builtins (pair, fst, snd, null), `s4+` are user-defined.

### Stage 2: Dataflow Graph Construction

**Builder** (`src/Synthesis/Builder.hs`): Lowers the checked AST into a dataflow graph — nodes are instructions, edges are data dependencies.

Key node types (`src/Synthesis/Node.hs`):
- **ALU**: `NAdd`, `NSub`, `NMul`, `NDiv`, `NAddI`, `NMulI`, etc.
- **Control**: `NSteer` (conditional routing), `NCallGroup`/`NCallSnd`/`NRetSnd`/`NRet` (function dispatch)
- **Tag manipulation**: `NTagVal`, `NValTag`, `NIncTag`, `NIncTagI` (dataflow routing tags)
- **Supers**: `NSuper` (opaque FFI call to Haskell code in libsupers.so)
- **Constants**: `NConstI`, `NConstF`, `NConstD`

### Stage 3: Code Generation

**Codegen** (`src/Synthesis/Codegen.hs`): Serializes the dataflow graph to TALM assembly text (`.fl` format). Each node becomes one TALM instruction with explicit input wiring.

### Stage 4: Super Extraction

**SuperExtract** (`src/Synthesis/SuperExtract.hs`) + **SupersEmit** (`src/Synthesis/SupersEmit.hs`): Extract `#BEGINSUPER`/`#ENDSUPER` blocks and generate a Haskell module (`Supers.hs`) with FFI-exported functions:
- `s0(pin, pout)`: pair constructor
- `s1(pin, pout)`: fst
- `s2(pin, pout)`: snd
- `s3(pin, pout)`: null check
- `sN(pin, pout)`: user-defined super (reads `Ptr Int64`, computes, writes `Ptr Int64`)

### Stage 5: Assembly & Placement

**FlowASM** (`TALM/asm/assembler.py`): Assembles `.fl` text into binary `.flb` and generates placement files `.pla` (manual) / `_auto.pla` (auto-scheduled).

```bash
python3 TALM/asm/assembler.py -a -n <PEs> -o <prefix> program.fl
# Produces: prefix.flb, prefix.pla, prefix_auto.pla
```

### Stage 6: Execution

**Trebuchet interpreter** (`TALM/interp/interp`): Multi-threaded dataflow execution engine. One POSIX thread per PE. Loads `.flb` bytecode + `.pla` placement + `libsupers.so` (optional).

```bash
TALM/interp/interp <n_PEs> <program.flb> <program.pla> [libsupers.so]
```

**Tag system**: Dataflow tokens carry a `uint64_t tag` field for routing in recursive/parallel contexts. Tags use base-9 encoding: `call: tag = tag * 9 + offset`, `return: tag = tag / 9`. With 64-bit tags, maximum recursion depth is ~19 levels (`9^20 ≈ 1.2×10^19 < 2^64`).

**Exec-only sentinels**: Negative values in `.value.li` signal exec-only matching mode (tag field ignored). Created by `retagToExecOnly` in Builder.hs via `sub 0 (tagval+1)`.

---

## Building

### Prerequisites

- GHC 9.4+ with `alex`, `happy`
- GCC (for C interpreter)
- Python 3 (for assembler and benchmark scripts)
- GraphViz `dot` (for visualization, optional)
- `matplotlib`, `numpy` (for paper figure generation)

### Build Commands

```bash
# Build everything (compiler executables + test artifacts + supers)
make all

# Build individual targets
make code              # Build codegen + generate .fl for all test programs
make ast               # Build analysis + generate AST DOTs and PNGs
make df                # Build synthesis + generate dataflow DOTs and PNGs
make supers            # Build supersgen + generate libsupers.so for all tests
make supers_prepare    # Set up GHC shim for RTS discovery (run before supers)

# Build the TALM interpreter
make -C TALM/interp

# Clean all build artifacts
make clean
```

**Important**: If you get ambiguous package errors from GHC, prefix commands with `GHC_ENVIRONMENT=-`:
```bash
GHC_ENVIRONMENT=- make code
```

### Makefile Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `GHC` | `ghc` | Haskell compiler |
| `ALEX` | `alex` | Lexer generator |
| `HAPPY` | `happy` | Parser generator |
| `DOT` | `dot` | GraphViz renderer |
| `SUPERS_THREADED` | `1` | Link supers against threaded RTS |
| `SUPERS_WRAPPERS_MAX` | `256` | Number of super wrapper slots |

---

## Running a Single Program

End-to-end execution of a `.hsk` program:

```bash
# 1. Generate TALM assembly
./codegen test/10_fibonacci.hsk > /tmp/fib.fl

# 2. Build supers library
CFLAGS="-O2 -fPIC -I$(ghc --print-libdir)/x86_64-linux-ghc-$(ghc --numeric-version)/rts-*/include" \
  bash tools/build_supers.sh test/10_fibonacci.hsk /tmp/Supers.hs

# 3. Assemble for N PEs
python3 TALM/asm/assembler.py -a -n 4 -o /tmp/fib /tmp/fib.fl

# 4. Run on the interpreter
TALM/interp/interp 4 /tmp/fib.flb /tmp/fib_auto.pla /tmp/libsupers.so
```

For a quick test with the pre-built test supers:
```bash
./codegen test/00_hello_world.hsk > /tmp/hello.fl
python3 TALM/asm/assembler.py -a -n 1 -o /tmp/hello /tmp/hello.fl
TALM/interp/interp 1 /tmp/hello.flb /tmp/hello_auto.pla test/supers/hello_world_super/libsupers.so
# Output: Hello World!
```

---

## Running All Benchmarks

Use `scripts/run_all.sh`. This is the single entry point for running all benchmarks. It orchestrates all 5 benchmarks (MergeSort, Dyck, Fibonacci, MatMul, Graph Coloring), each comparing three backends: Ribault/TALM (superinstructions), GHC Strategies, and GHC par/pseq.

### Run with paper defaults (full sweep, ~20,700 runs, takes hours)

```bash
bash scripts/run_all.sh
```

Paper defaults:

| Benchmark | N range | Other params | Reps | Procs |
|-----------|---------|--------------|------|-------|
| MergeSort | 50K–1M step 50K | | 10 | 1,2,4,8 |
| Dyck | 50K–1M step 50K | imb=0–100 step 5, delta=0 | 3 | 1,2,4,8 |
| Fibonacci | 35 | cutoff=15,20,25,30 | 3 | 1,2,4,8 |
| MatMul | 50–1000 step 50 | | 10 | 1,2,4,8 |
| Graph Coloring | 50–1000 step 50 | edge_prob=0.01, seed=42 | 3 | 1,2,4,8 |

### Quick smoke test

```bash
bash scripts/run_all.sh --reps 1 --procs 1,2 \
  --ms-start-N 100000 --ms-max-N 200000 \
  --dyck-N 50000 --dyck-imb 0,50,100 \
  --fib-cutoff 25,30 \
  --matmul-N 100,200 \
  --gc-N 50,100
```

### Full heavy run (each benchmark ≥ 20 min on TALM)

This command extends the N ranges beyond the paper defaults so that **each benchmark's TALM portion alone takes at least 20 minutes**. All ranges start at the same initial N as the paper results. GHC (Strategies + par/pseq) runs after TALM for each benchmark and takes additional time on top.

```bash
bash scripts/run_all.sh --procs 1,2,4,8 \
  --ms-start-N 50000 --ms-step 50000 --ms-max-N 20000000 --ms-reps 10 \
  --dyck-N "$(seq -s, 50000 50000 25000000)" --dyck-imb "$(seq -s, 0 5 100)" --dyck-reps 3 \
  --fib-N 35 --fib-cutoff 15,20,25,30 --fib-reps 3 \
  --matmul-N "$(seq -s, 50 50 1500)" --matmul-reps 10 \
  --gc-N "$(seq -s, 50 50 1000)" --gc-reps 3 --gc-edge-prob 0.01 --gc-seed 42
```

Estimated TALM-only times (on a typical 8-core machine):

| Benchmark      | N range             | Runs   | Est. TALM time |
|----------------|---------------------|--------|----------------|
| MergeSort      | 50K → 20M step 50K  | 16,000 | ~30 min        |
| Dyck           | 50K → 25M step 50K  |126,000 | ~25 min        |
| Fibonacci      | N=35, cut=15,20,25,30| 48    | ~140 min       |
| MatMul         | 50 → 1500 step 50   | 1,200  | ~30 min        |
| Graph Coloring | 50 → 1000 step 50   | 240    | ~23 min        |

Total estimated wall time (TALM + GHC Strategies + GHC par/pseq): **several hours**.

### Selective runs

```bash
bash scripts/run_all.sh --only mergesort,fibonacci   # only these two
bash scripts/run_all.sh --skip dyck,graph_coloring   # skip these two
bash scripts/run_all.sh --dry-run                     # print config, don't execute
```

### Skip specific backends

```bash
SKIP_TALM=1 bash scripts/run_all.sh                       # skip Ribault, only GHC variants
SKIP_GHC=1 SKIP_PARPSEQ=1 bash scripts/run_all.sh         # only Ribault
```

(`SKIP_SUPER=1` is equivalent to `SKIP_TALM=1`, used by dyck/gc scripts internally.)

### All `run_all.sh` flags

**Global:**

| Flag | Default | Description |
|------|---------|-------------|
| `--procs <csv>` | `1,2,4,8` | PE counts to benchmark |
| `--reps <n>` | per-benchmark | Override all benchmark reps |
| `--outdir <dir>` | `RESULTS` | Results root directory |
| `--only <csv>` | all | Run only listed benchmarks: `mergesort`, `dyck`, `fibonacci`, `matmul`, `graph_coloring` |
| `--skip <csv>` | none | Skip listed benchmarks |
| `--dry-run` | off | Print config and exit |
| `-h`, `--help` | | Show help |

**MergeSort:**

| Flag | Default | Description |
|------|---------|-------------|
| `--ms-start-N <n>` | `50000` | Starting array size |
| `--ms-step <n>` | `50000` | Step increment |
| `--ms-max-N <n>` | `1000000` | Maximum array size |
| `--ms-N <csv>` | generated from start/step/max | Explicit N values (overrides start/step/max) |
| `--ms-reps <n>` | `--reps` or `10` | Repetitions |

**Dyck:**

| Flag | Default | Description |
|------|---------|-------------|
| `--dyck-N <csv>` | `50000..1000000` step 50K | Sequence lengths |
| `--dyck-imb <csv>` | `0..100` step 5 | Workload imbalance percentages |
| `--dyck-delta <csv>` | `0` | Delta parameter |
| `--dyck-reps <n>` | `--reps` or `3` | Repetitions |

**Fibonacci:**

| Flag | Default | Description |
|------|---------|-------------|
| `--fib-N <csv>` | `35` | Which fib(N) to compute |
| `--fib-cutoff <csv>` | `15,20,25,30` | Sequential cutoff thresholds |
| `--fib-reps <n>` | `--reps` or `3` | Repetitions |

**MatMul:**

| Flag | Default | Description |
|------|---------|-------------|
| `--matmul-N <csv>` | `50..1000` step 50 | Matrix dimension N×N |
| `--matmul-reps <n>` | `--reps` or `10` | Repetitions |

**Graph Coloring:**

| Flag | Default | Description |
|------|---------|-------------|
| `--gc-N <csv>` | `50..1000` step 50 | Number of vertices |
| `--gc-reps <n>` | `--reps` or `3` | Repetitions |
| `--gc-edge-prob <f>` | `0.01` | Edge probability (Erdos-Renyi) |
| `--gc-seed <n>` | `42` | Random seed |

**Environment variables** (passed through to per-benchmark scripts):

| Variable | Default | Effect |
|----------|---------|--------|
| `SKIP_TALM=1` / `SKIP_SUPER=1` | off | Skip Ribault/TALM runs |
| `SKIP_GHC=1` | off | Skip GHC Strategies runs |
| `SKIP_PARPSEQ=1` | off | Skip GHC par/pseq runs |
| `PY2`, `PY3` | `python3` | Python interpreters for assembler/generators |
| `MS_LEAF` | `array` | MergeSort leaf node type: `array`, `super`, `coarse`, `asm` |
| `CUTOFF_MODE` | `fixed` | MergeSort cutoff strategy: `fixed`, `scaled`, `perP`, `balanced`, `grain` |
| `CUTOFF` | `4096` | MergeSort base cutoff threshold |
| `DF_LIST_BUILTIN` | `1` | MergeSort: use dataflow list builtin encoding |
| `PLACE_MODE` | `rr` | Dyck/GC: placement strategy (`rr` or `chunk`) |
| `SUPERS_FIXED` | (none) | Dyck/GC: path to pre-built supers directory |

### Output

Results go to `RESULTS/` (or `--outdir`):
```
RESULTS/mergesort/metrics_ms_{super,ghc,parpseq}.csv
RESULTS/dyck_N_IMB_sweep/metrics_dyck_{super,ghc,parpseq}.csv
RESULTS/fibonacci/metrics_fib_{talm,ghc,parpseq}.csv
RESULTS/matmul/metrics_matmul_{talm,ghc,parpseq}.csv
RESULTS/graph_coloring/metrics_gc_{super,ghc,parpseq}.csv
```

`run_all.sh` prints a summary at the end with run counts per file and total errors.

---

## Benchmark Details

### MergeSort Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--ms-start-N <n>` | `50000` | Starting array size |
| `--ms-step <n>` | `50000` | Step increment for N |
| `--ms-max-N <n>` | `1000000` | Maximum array size |
| `--ms-N <csv>` | (generated from start/step/max) | Explicit N values. Overrides `--ms-start-N`, `--ms-step`, `--ms-max-N` |
| `--ms-reps <n>` | `--reps` or `10` | Number of repetitions per configuration |

**What it measures**: Runtime to sort a randomly-generated integer array of size N using parallel merge sort. The TALM version uses superinstructions for the sequential merge kernel; GHC versions use `Control.Parallel.Strategies` or explicit `par`/`pseq`.

**MergeSort-specific environment variables** (for the underlying `run.sh`):

| Variable | Default | Description |
|----------|---------|-------------|
| `MS_LEAF` | `array` | Leaf node type: `array`, `super`, `coarse`, `asm` |
| `CUTOFF_MODE` | `fixed` | Cutoff strategy: `fixed`, `scaled`, `perP`, `balanced`, `grain`, etc. |
| `CUTOFF` | `4096` | Base cutoff threshold (below this, use sequential sort) |
| `DF_LIST_BUILTIN` | `1` | Use dataflow list builtin encoding |
| `SEQ_P1` | `0` | If `1`, use fully sequential version for P=1 |

**Output**: `RESULTS/mergesort/metrics_ms_{super,ghc,parpseq}.csv`

**Correctness guard**: Checks output is sorted (rc=99 if not, rc=98 if missing).

---

### Dyck Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--dyck-N <csv>` | `50000,100000,…,1000000` (step 50000) | Sequence lengths |
| `--dyck-imb <csv>` | `0,5,10,…,100` (step 5) | Workload imbalance percentages (0% = balanced, 100% = all work on one PE) |
| `--dyck-delta <csv>` | `0` | Delta parameter (shift in Dyck path nesting) |
| `--dyck-reps <n>` | `--reps` or `3` | Repetitions per configuration |

**What it measures**: Runtime to process a Dyck sequence (balanced parentheses) of length N with configurable workload imbalance. Tests Ribault's resilience to load imbalance vs GHC's static partitioning.

**Dyck-specific environment variables**:

| Variable | Default | Description |
|----------|---------|-------------|
| `PLACE_MODE` | `rr` | Placement strategy: `rr` (round-robin) or `chunk` |
| `SUPERS_FIXED` | (none) | Path to pre-built supers directory (skip per-N compilation) |

**Output**: `RESULTS/dyck_N_IMB_sweep/metrics_dyck_{super,ghc,parpseq}.csv`

**Correctness guard**: Checks computed result matches expected value for given delta (rc=99 if wrong).

---

### Fibonacci Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--fib-N <csv>` | `35` | Fibonacci number to compute |
| `--fib-cutoff <csv>` | `15,20,25,30` | Cutoff thresholds (below cutoff, switch to sequential iterative fib) |
| `--fib-reps <n>` | `--reps` or `3` | Repetitions per configuration |

**What it measures**: Runtime to compute fib(N) using parallel recursive decomposition with a sequential cutoff. Lower cutoff = more parallelism (more dataflow tasks) but deeper recursion. Tests the tag system's depth limit and parallel overhead.

**Cutoff semantics**: For fib(35) with cutoff=C, the recursion tree has depth 35−C. Each parallel call multiplies the tag by 9 (base-9 encoding). With 64-bit tags, maximum depth is ~19 levels, so cutoff >= 16 for fib(35).

**Output**: `RESULTS/fibonacci/metrics_fib_{talm,ghc,parpseq}.csv`

**Correctness guard**: Computes expected fib(N) via Python, compares with `RESULT=` line in stdout (rc=99 if wrong). Note: cutoff=15 (depth 20) may produce missing output for TALM (warned but not failed).

---

### MatMul Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--matmul-N <csv>` | `50,100,…,1000` (step 50) | Matrix dimension (N×N multiply) |
| `--matmul-reps <n>` | `--reps` or `10` | Repetitions per configuration |

**What it measures**: Runtime to multiply two N×N integer matrices using block decomposition. The TALM version partitions the matrix into P blocks (one per PE) and uses superinstructions for the sequential inner loops.

**Output**: `RESULTS/matmul/metrics_matmul_{talm,ghc,parpseq}.csv`

**Correctness guard**: Computes reference checksum via Python, compares with `CHECKSUM=` line (rc=99 if wrong).

---

### Graph Coloring Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--gc-N <csv>` | `50,100,…,1000` (step 50) | Number of graph vertices |
| `--gc-reps <n>` | `--reps` or `3` | Repetitions per configuration |
| `--gc-edge-prob <f>` | `0.01` | Edge probability for random graph generation (Erdos-Renyi model) |
| `--gc-seed <n>` | `42` | Random seed for graph generation (reproducibility) |

**What it measures**: Runtime to greedily color a random graph with N vertices. Each PE colors its assigned chunk of vertices, respecting adjacency constraints. Tests irregular parallelism with shared-state coordination.

**Graph coloring-specific environment variables**:

| Variable | Default | Description |
|----------|---------|-------------|
| `PLACE_MODE` | `rr` | Placement strategy: `rr` (round-robin) or `chunk` |
| `SUPERS_FIXED` | (none) | Path to pre-built supers directory |

**Output**: `RESULTS/graph_coloring/metrics_gc_{super,ghc,parpseq}.csv`

**Correctness guard**: Checks `valid=1` in output (all adjacent vertices have different colors). rc=99 if `valid=0`.

---

### Metrics CSV Format

All benchmarks produce CSV files with this structure:

```
variant,N,[benchmark-specific params],P,rep,seconds,rc
super,100000,1,1,0.042,0
ghc,100000,1,1,0.038,0
```

| Column | Description |
|--------|-------------|
| `variant` | `super`/`talm` (Ribault), `ghc` (GHC Strategies), `parpseq` (GHC par/pseq) |
| `N` | Problem size |
| `P` | Number of PEs/threads |
| `rep` | Repetition number |
| `seconds` | Wall-clock runtime |
| `rc` | Return code: `0` = success, `98` = missing output, `99` = wrong answer |

---

## Paper Figure Generation

After benchmarks complete, generate all publication figures:

```bash
# Generate benchmark comparison figures (fig1–fig12)
python3 scripts/paper_figures.py --results RESULTS --outdir RESULTS/paper_figures

# Generate pipeline and DFG diagrams (fig2_pipeline, fig4_mergesort_dfg)
python3 scripts/gen_paper_fig2_fig4.py --outdir RESULTS/paper_figures
```

### Figures Produced

| Figure | File | Description |
|--------|------|-------------|
| Fig 1 | `fig1_matmul_best_runtime` | MatMul: best runtime vs N (3 systems) |
| Fig 2 | `fig2_matmul_best_speedup` | MatMul: best speedup vs N |
| Fig 2 | `fig2_pipeline` | Compiler pipeline diagram |
| Fig 3 | `fig3_ms_best_runtime` | MergeSort: best runtime vs N (log scale) |
| Fig 4 | `fig4_mergesort_dfg` | MergeSort dataflow graph diagram |
| Fig 4 | `fig4_ms_advantage` | MergeSort: Ribault advantage ratio vs N |
| Fig 5 | `fig5_dyck_imbalance` | Dyck: runtime vs imbalance (P=8, log scale) |
| Fig 6 | `fig6_dyck_collapse_scaling` | Dyck: worst-case scaling (100% imbalance) |
| Fig 7 | `fig7_summary_barplot` | Consolidated bar chart across all benchmarks |
| Fig 8 | `fig8_matmul_ribault_perP` | MatMul: Ribault scaling by P |
| Fig 9 | `fig9_ms_ribault_perP` | MergeSort: Ribault scaling by P |
| Fig 10 | `fig10_dyck_ribault_perP` | Dyck: Ribault scaling by P |
| Fig 11 | `fig11_fib_ribault_perP` | Fibonacci: Ribault scaling by P |
| Fig 12 | `fig12_fib_best_runtime` | Fibonacci: best runtime vs cutoff (3 systems) |

---

## Key Implementation Details

### Tag System (64-bit)

Tags route dataflow tokens through recursive/parallel call structures. Defined in `TALM/interp/include/interp.h`:

```c
struct oper {
    uint64_t tag;       // 64-bit routing tag
    int exec;           // execution context
    generic_vartype value;  // union: int i, long int li, float f, double d, void *p
};
```

- **Encoding**: Base-9. Call: `tag = tag * 9 + offset`. Return: `tag = tag / 9`.
- **Depth limit**: `9^20 ≈ 1.2×10^19 < 2^64`, so max depth ~19 levels.
- **TAGVAL instruction**: Copies tag field to `.value.li` for arithmetic.
- **VALTAG instruction**: Writes `.value.li` back to tag field. If `.value.li < 0`, it's an exec-only sentinel (tag is `-(value+1)`).

### Superinstructions

Supers are opaque Haskell functions compiled into `libsupers.so`, called by the interpreter via `dlopen`/`dlsym`:

```haskell
-- Profile: sN :: Ptr Int64 -> Ptr Int64 -> IO ()
foreign export ccall "s4" s4 :: Ptr Int64 -> Ptr Int64 -> IO ()
s4 pin pout = do
  x <- peek pin
  let result = {- user-defined computation -}
  poke pout result
```

Reserved supers (s0–s3): pair constructor, fst, snd, null check — used for list encoding in dataflow.

### Interpreter CLI

```
TALM/interp/interp <n_PEs> <program.flb> <program.pla> [libsupers.so]
```

| Argument | Description |
|----------|-------------|
| `n_PEs` | Number of processing elements (threads). Must be >= 1 |
| `program.flb` | Assembled binary bytecode |
| `program.pla` | Placement file (PE assignment per instruction) |
| `libsupers.so` | Optional shared library with superinstruction implementations |

Output: `EXEC_TIME_S <seconds>` printed to stderr. Program stdout contains application output.

### Assembler CLI

```
python3 TALM/asm/assembler.py [options] program.fl
```

| Flag | Description |
|------|-------------|
| `-n <N>` | Number of tasks/PEs for placement |
| `-o <prefix>` | Output file prefix (produces `prefix.flb`, `prefix.pla`) |
| `-a` | Enable auto-placement (produces `prefix_auto.pla`) |

---

## Per-Benchmark Script Reference

Each benchmark has its own `run_compare.sh` that orchestrates all three variants. These are called by `run_all.sh` but can also be invoked directly.

### Common Flags (all `run_compare.sh`)

| Flag | Description |
|------|-------------|
| `--interp <path>` | Path to TALM interpreter binary |
| `--asm-root <path>` | Path to TALM/asm directory |
| `--codegen <path>` | Path to repo root (containing `codegen` binary) |
| `--outroot <dir>` | Output directory for results |
| `--tag <name>` | Prefix for metrics CSV filenames |
| `--procs <csv>` | PE counts to test |
| `--reps <n>` | Repetitions |

### MergeSort (`scripts/merge_sort_TALM_vs_Haskell/run_compare.sh`)

```bash
bash scripts/merge_sort_TALM_vs_Haskell/run_compare.sh \
  --start-N 50000 --step 50000 --n-max 1000000 \
  --reps 10 --procs "1,2,4,8" \
  --interp TALM/interp/interp --asm-root TALM/asm --codegen . \
  --outroot RESULTS/mergesort --tag ms
```

### Dyck (`scripts/dyck/run_compare.sh`)

```bash
bash scripts/dyck/run_compare.sh \
  --N "50000,100000,500000,1000000" \
  --imb "0,25,50,75,100" --delta "0" \
  --reps 3 --procs "1,2,4,8" \
  --interp TALM/interp/interp --asm-root TALM/asm --codegen . \
  --outroot RESULTS/dyck_N_IMB_sweep --tag dyck
```

### Fibonacci (`scripts/fibonacci/run_compare.sh`)

```bash
bash scripts/fibonacci/run_compare.sh \
  --N "35" --cutoff "15,20,25,30" \
  --reps 3 --procs "1,2,4,8" \
  --interp TALM/interp/interp --asm-root TALM/asm --codegen . \
  --outroot RESULTS/fibonacci --tag fib
```

### MatMul (`scripts/matmul/run_compare.sh`)

```bash
bash scripts/matmul/run_compare.sh \
  --N "100,200,500,1000" \
  --reps 10 --procs "1,2,4,8" \
  --interp TALM/interp/interp --asm-root TALM/asm --codegen . \
  --outroot RESULTS/matmul --tag matmul
```

### Graph Coloring (`scripts/graph_coloring/run_compare.sh`)

```bash
bash scripts/graph_coloring/run_compare.sh \
  --N "100,200,500,1000" \
  --reps 3 --procs "1,2,4,8" \
  --edge-prob 0.01 --seed 42 \
  --interp TALM/interp/interp --asm-root TALM/asm --codegen . \
  --outroot RESULTS/graph_coloring --tag gc
```

---

## Source Language (.hsk)

Ribault compiles a subset of Haskell with these constructs:

```haskell
-- Function definitions
f x y = x + y

-- If/then/else
abs n = if n < 0 then 0 - n else n

-- Let/in bindings
g x = let a = x + 1
          b = a * 2
      in a + b

-- Case expressions
head xs = case xs of
  (x:_) -> x

-- Lists
sum [] = 0
sum (x:xs) = x + sum xs

-- Superinstructions (opaque Haskell blocks)
fast_sort xs =
  super single input (xs) output (out)
#BEGINSUPER
    out = Data.List.sort xs
#ENDSUPER

-- Main entry point
main = f 3 4
```

**Super blocks**: Code between `#BEGINSUPER` and `#ENDSUPER` is extracted verbatim into `Supers.hs` and compiled as a Haskell shared library. The dataflow graph treats supers as opaque single-input/single-output nodes. This allows mixing optimized sequential Haskell with Ribault's parallel dataflow execution.
